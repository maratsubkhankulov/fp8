{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to py39 (Python 3.9.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the current file's directory to the Python path\n",
    "current_dir = os.path.dirname(os.path.abspath('..'))\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "from solution import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65536]) tensor([0.0000e+00, 9.1835e-41, 1.8367e-40,  ...,        nan,        nan,\n",
      "               nan], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Construct the full range of bfloat16\n",
    "y = torch.arange(0, 2**16, dtype=torch.int32)\n",
    "y = bits_to_bfloat16(y)\n",
    "print(y.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65536]) tensor([    0,     1,     2,  ..., 65533, 65534, 65535], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "z = bfloat16_to_bits(y)\n",
    "print(z.shape, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256]) tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Construct the full range of uint8\n",
    "x = torch.arange(0, 2**8, dtype=torch.int32)\n",
    "print(x.shape, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 1, 1, 1], dtype=torch.int32) tensor([  0,   0,   0,  ..., 255, 255, 255], dtype=torch.int32) tensor([  0,   1,   2,  ..., 125, 126, 127], dtype=torch.int32)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32) tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15], dtype=torch.int32) tensor([0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7], dtype=torch.int32)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32) tensor([ 0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3,  4,  4,\n",
      "         4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  8,\n",
      "         9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 12, 13, 13,\n",
      "        13, 13, 14, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 16, 17, 17, 17, 17,\n",
      "        18, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
      "        22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "        27, 27, 27, 27, 28, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30, 31, 31,\n",
      "        31, 31,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "         4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,  7,  8,  8,\n",
      "         8,  8,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 12,\n",
      "        13, 13, 13, 13, 14, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 16, 17, 17,\n",
      "        17, 17, 18, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21,\n",
      "        22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26,\n",
      "        26, 26, 27, 27, 27, 27, 28, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30,\n",
      "        31, 31, 31, 31], dtype=torch.int32) tensor([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(*decompose_16bit(z))\n",
    "print(*decompose_8bit_e4m3(x))\n",
    "print(*decompose_8bit_e5m2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "sign, exponent, mantissa = decompose_16bit(z)\n",
    "bits = compose_16bit(sign, exponent, mantissa)\n",
    "print(torch.equal(bits, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that you can convert bfloat16 to bits and back\n",
    "y_ = bits_to_bfloat16(\n",
    "    bfloat16_to_bits(y)\n",
    ")\n",
    "comparison = torch.isclose(\n",
    "        y,\n",
    "        y_\n",
    ")\n",
    "comparison[torch.isnan(y) & torch.isnan(y_)] = True\n",
    "comparison.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that you can convert bfloat16 to bits, decompose, recompose and convert back\n",
    "y_bits = bfloat16_to_bits(y)\n",
    "components = decompose_16bit(y_bits)\n",
    "y_bits_ = compose_16bit(*components)\n",
    "y_ = bits_to_bfloat16(y_bits_)\n",
    "\n",
    "comparison = torch.isclose(\n",
    "        y,\n",
    "        y_\n",
    ")\n",
    "comparison[torch.isnan(y) & torch.isnan(y_)] = True\n",
    "comparison.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([inf], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Construct infinity\n",
    "s = torch.tensor([0], dtype=torch.int32)\n",
    "e = torch.tensor([0xFF], dtype=torch.int32)\n",
    "m = torch.tensor([0], dtype=torch.int32)\n",
    "n = bits_to_bfloat16(compose_16bit(s, e, m))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([nan], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Construct nan\n",
    "s = torch.tensor([0], dtype=torch.int32)\n",
    "e = torch.tensor([0xFF], dtype=torch.int32)\n",
    "m = torch.tensor([1], dtype=torch.int32)\n",
    "n = bits_to_bfloat16(compose_16bit(s, e, m))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3125], dtype=torch.bfloat16) tensor([0.3125], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Test bfloat16 to e5m2 and back\n",
    "t = torch.tensor([0.3125], dtype=torch.bfloat16)\n",
    "t_bits = bfloat16_to_bits(t)\n",
    "\n",
    "encoded = encode_as_e5m2(t_bits)\n",
    "decoded = decode_from_e5m2(encoded)\n",
    "t_quantized = bits_to_bfloat16(decoded)\n",
    "print(t, t_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([0.2178], dtype=torch.bfloat16)\n",
      "Quantized: tensor([0.2188], dtype=torch.bfloat16)\n",
      "Rounded up correctly: tensor([True])\n"
     ]
    }
   ],
   "source": [
    "# Test rounding up when converting from bfloat16 to e5m2\n",
    "s = torch.tensor([0], dtype=torch.int32)\n",
    "e = torch.tensor([0b01111100], dtype=torch.int32)\n",
    "m = torch.tensor([0b1011111], dtype=torch.int32)  # Changed to 1011111 to test rounding up\n",
    "t_bits = compose_16bit(s, e, m)\n",
    "t = bits_to_bfloat16(t_bits)  # This is 0 01111100 1011111 in binary\n",
    "\n",
    "encoded = encode_as_e5m2_round_up(t_bits)\n",
    "decoded = decode_from_e5m2(encoded)\n",
    "t_quantized = bits_to_bfloat16(decoded)\n",
    "\n",
    "# Construct the rounded up e5m2 value\n",
    "encoded_e5m2 = encode_as_e5m2(t_bits)\n",
    "s, e, m = decompose_8bit_e5m2(encoded_e5m2)\n",
    "\n",
    "# Manually round up (without worrying about mantissa overflow)\n",
    "m += 1\n",
    "\n",
    "# Compose the rounded e5m2 value\n",
    "rounded_e5m2 = compose_e5m2(s, e, m)\n",
    "\n",
    "# Convert back to bfloat16 using decode_from_e5m2\n",
    "decoded_bits = decode_from_e5m2(rounded_e5m2)\n",
    "t_expected = bits_to_bfloat16(decoded_bits)\n",
    "\n",
    "print(\"Original:\", t)\n",
    "print(\"Quantized:\", t_quantized)\n",
    "print(\"Rounded up correctly:\", torch.isclose(t_quantized, t_expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding-decoding process is reversible for all e5m2 values: True\n"
     ]
    }
   ],
   "source": [
    "# Test encode_as_e5m2 and decode_as_e5m2 for all possible e5m2 values\n",
    "\n",
    "# Generate all possible 8-bit values (0 to 255)\n",
    "all_e5m2_values = torch.arange(0, 256, dtype=torch.uint8)\n",
    "\n",
    "# Convert to int32 for compatibility with our functions\n",
    "all_e5m2_int32 = all_e5m2_values.to(dtype=torch.int32)\n",
    "\n",
    "# Decode all e5m2 values to bfloat16 bits\n",
    "decoded_bits = decode_from_e5m2(all_e5m2_int32)\n",
    "\n",
    "# Convert to bfloat16\n",
    "bfloat16_values = bits_to_bfloat16(decoded_bits)\n",
    "\n",
    "# Encode back to e5m2\n",
    "encoded_e5m2 = encode_as_e5m2(bfloat16_to_bits(bfloat16_values))\n",
    "\n",
    "# Check if the encoding-decoding process is reversible\n",
    "is_reversible = torch.all(encoded_e5m2 == all_e5m2_int32)\n",
    "\n",
    "print(f\"Encoding-decoding process is reversible for all e5m2 values: {is_reversible}\")\n",
    "\n",
    "# Additional checks\n",
    "if not is_reversible:\n",
    "    # Find where the mismatch occurs\n",
    "    mismatch = encoded_e5m2 != all_e5m2_int32\n",
    "    mismatch_indices = torch.where(mismatch)[0]\n",
    "    print(f\"Mismatches found at indices: {mismatch_indices}\")\n",
    "    \n",
    "    # Print a few mismatched values for inspection\n",
    "    for idx in mismatch_indices[:5]:  # Show first 5 mismatches\n",
    "        original = all_e5m2_int32[idx].item()\n",
    "        encoded = encoded_e5m2[idx].item()\n",
    "        print(f\"Index {idx}: Original {original:08b}, Encoded {encoded:08b}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounding process preserves order (ignoring NaNs): False\n"
     ]
    }
   ],
   "source": [
    "# Test round_to_fp8_represented_as_int8() and undo_int8_fp8() for all bfloat16 values\n",
    "\n",
    "# Generate all possible 16-bit values (0 to 65535)\n",
    "all_bfloat16_values = torch.arange(0, 2**16, dtype=torch.int32)\n",
    "\n",
    "# Convert to bfloat16\n",
    "bfloat16_values = bits_to_bfloat16(all_bfloat16_values)\n",
    "\n",
    "# Round to fp8 (e5m2)\n",
    "fp8_values = round_to_fp8_represented_as_int8(bfloat16_values, n_mantissa=2)\n",
    "\n",
    "# Convert back to bfloat16\n",
    "recovered_bfloat16 = undo_int8_fp8(fp8_values, n_mantissa=2)\n",
    "\n",
    "# Create a mask for non-NaN values\n",
    "non_nan_mask = ~torch.isnan(bfloat16_values) & ~torch.isnan(recovered_bfloat16)\n",
    "\n",
    "# Check if the rounding process preserves order (ignoring NaNs)\n",
    "is_order_preserved = torch.all(torch.argsort(bfloat16_values[non_nan_mask]) == torch.argsort(recovered_bfloat16[non_nan_mask]))\n",
    "\n",
    "print(f\"Rounding process preserves order (ignoring NaNs): {is_order_preserved}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.,  2.,  2.,  ..., -1., -1., -1.], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(recovered_bfloat16[non_nan_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inf values preserved: False\n",
      "NaN values preserved: False\n",
      "Zero values preserved: False\n",
      "Non-special values are close (ignoring NaNs): False\n",
      "Number of values not close: 55024\n",
      "Max absolute difference: 3.3895313892515355e+38\n",
      "Mean absolute difference: inf\n",
      "Average stochastic result is close to original (ignoring NaNs): False\n",
      "Number of average values not close: 55301\n",
      "Max absolute difference in averages: inf\n",
      "Mean absolute difference in averages: inf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for special cases\n",
    "inf_mask = torch.isinf(bfloat16_values)\n",
    "nan_mask = torch.isnan(bfloat16_values)\n",
    "zero_mask = bfloat16_values == 0\n",
    "\n",
    "print(f\"Inf values preserved: {torch.all(torch.isinf(recovered_bfloat16[inf_mask]))}\")\n",
    "print(f\"NaN values preserved: {torch.all(torch.isnan(recovered_bfloat16[nan_mask]))}\")\n",
    "print(f\"Zero values preserved: {torch.all(recovered_bfloat16[zero_mask] == 0)}\")\n",
    "\n",
    "# Check if values are close within fp8 precision (ignoring NaNs)\n",
    "non_special_mask = ~(inf_mask | nan_mask | zero_mask)\n",
    "is_close = torch.isclose(bfloat16_values[non_special_mask], recovered_bfloat16[non_special_mask], rtol=1e-2, atol=1e-2)\n",
    "print(f\"Non-special values are close (ignoring NaNs): {torch.all(is_close)}\")\n",
    "\n",
    "# If not all values are close, print some statistics\n",
    "if not torch.all(is_close):\n",
    "    not_close = ~is_close\n",
    "    print(f\"Number of values not close: {torch.sum(not_close)}\")\n",
    "    print(f\"Max absolute difference: {torch.max(torch.abs(bfloat16_values[non_special_mask][not_close] - recovered_bfloat16[non_special_mask][not_close]))}\")\n",
    "    print(f\"Mean absolute difference: {torch.mean(torch.abs(bfloat16_values[non_special_mask][not_close] - recovered_bfloat16[non_special_mask][not_close]))}\")\n",
    "\n",
    "# Test for stochastic rounding\n",
    "num_rounds = 1000\n",
    "stochastic_results = torch.zeros_like(bfloat16_values)\n",
    "\n",
    "for _ in range(num_rounds):\n",
    "    fp8_values = round_to_fp8_represented_as_int8(bfloat16_values, n_mantissa=2)\n",
    "    recovered = undo_int8_fp8(fp8_values, n_mantissa=2)\n",
    "    stochastic_results += recovered\n",
    "\n",
    "average_result = stochastic_results / num_rounds\n",
    "\n",
    "# Check if the average result is close to the original values (ignoring NaNs)\n",
    "non_nan_mask = ~torch.isnan(bfloat16_values) & ~torch.isnan(average_result)\n",
    "is_average_close = torch.isclose(bfloat16_values[non_nan_mask], average_result[non_nan_mask], rtol=1e-2, atol=1e-2)\n",
    "print(f\"Average stochastic result is close to original (ignoring NaNs): {torch.all(is_average_close)}\")\n",
    "\n",
    "# If not all average values are close, print some statistics\n",
    "if not torch.all(is_average_close):\n",
    "    not_close = ~is_average_close\n",
    "    print(f\"Number of average values not close: {torch.sum(not_close)}\")\n",
    "    print(f\"Max absolute difference in averages: {torch.max(torch.abs(bfloat16_values[non_nan_mask][not_close] - average_result[non_nan_mask][not_close]))}\")\n",
    "    print(f\"Mean absolute difference in averages: {torch.mean(torch.abs(bfloat16_values[non_nan_mask][not_close] - average_result[non_nan_mask][not_close]))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are able to:\n",
    "- Construct the full range of bfloat16, uint8\n",
    "- Convert bfloat16 to bits and back\n",
    "- Convert bfloat16 to sign, exponent, mantissa and back\n",
    "- Test that conversion is correct except NaN values\n",
    "- Truncate when bfloat16 to e5m2 with mantissa chopping\n",
    "- Round up when converting from bfloat16 to e5m2\n",
    "\n",
    "Next:\n",
    "- Handle subnormal, inf, nan special cases in encode and decode \n",
    "- Round by stochastic rounding scheme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
