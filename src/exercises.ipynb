{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to py39 (Python 3.9.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the current file's directory to the Python path\n",
    "current_dir = os.path.dirname(os.path.abspath('..'))\n",
    "if current_dir not in sys.path:\n",
    "    sys.path.append(current_dir)\n",
    "\n",
    "from solution import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "e5m2 = {\n",
    "    \"0\":                  0b0_00000_00,\n",
    "    \"smallest_subnormal\": 0b0_00000_01,\n",
    "    \"largest_subnormal\":  0b0_00000_11,\n",
    "    \"smallest_normal\":    0b0_00001_00,\n",
    "    \"largest_normal\":     0b0_11110_11,\n",
    "    \"inf\":                0b0_11111_00,\n",
    "    \"nan1\":               0b0_11111_01,\n",
    "    \"nan2\":               0b0_11111_10,\n",
    "    \"nan3\":               0b0_11111_11,\n",
    "    \"-0\":                 0b1_00000_00,\n",
    "    \"-smallest_subnormal\":0b1_00000_01,\n",
    "    \"-largest_subnormal\": 0b1_00000_11,\n",
    "    \"-smallest_normal\":   0b1_00001_00,\n",
    "    \"-largest_normal\":    0b1_11110_11,\n",
    "    \"-inf\":               0b1_11111_00,\n",
    "    \"nan4\":               0b1_11111_01,\n",
    "    \"nan5\":               0b1_11111_10,\n",
    "    \"nan6\":               0b1_11111_11,\n",
    "}\n",
    "\n",
    "e4m3 = {\n",
    "    \"0\":                  0b0_0000_000,\n",
    "    \"smallest_subnormal\": 0b0_0000_001,\n",
    "    \"largest_subnormal\":  0b0_0000_111,\n",
    "    \"smallest_normal\":    0b0_0001_000,\n",
    "    \"largest_normal\":     0b0_1110_111,\n",
    "    \"largest_normal_ext\": 0b0_1111_110,\n",
    "    \"nan1\":               0b0_1111_111,\n",
    "    \"-0\":                 0b1_0000_000,\n",
    "    \"-smallest_subnormal\":0b1_0000_001,\n",
    "    \"-largest_subnormal\": 0b1_0000_111,\n",
    "    \"-smallest_normal\":   0b1_0001_000,\n",
    "    \"-largest_normal\":    0b1_1110_111,\n",
    "    \"-largest_normal_ext\":0b1_1111_110,\n",
    "    \"nan2\":               0b1_1111_111,\n",
    "}\n",
    "\n",
    "nan_values = {\n",
    "    2: {\n",
    "        e5m2['nan1'],\n",
    "        e5m2['nan2'],\n",
    "        e5m2['nan3'],\n",
    "        e5m2['nan4'],\n",
    "        e5m2['nan5'],\n",
    "        e5m2['nan6'],\n",
    "    },\n",
    "    3: {\n",
    "        e4m3['nan1'],\n",
    "        e4m3['nan2'],\n",
    "    }\n",
    "}\n",
    "n_mantissa = 2\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 1.3984, 0.6016], dtype=torch.bfloat16)\n",
      "tensor([ 0, 61, 56], dtype=torch.uint8)\n",
      "tensor([0, 0, 0], dtype=torch.int32) tensor([ 0, 15, 14], dtype=torch.int32) tensor([0, 1, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "n_mantissa = 2\n",
    "y = torch.tensor([0.0, 1.4, 0.6], dtype=torch.bfloat16)\n",
    "x = bfloat16_to_fp8(y, n_mantissa, rounding='trunc')\n",
    "print(y)\n",
    "print(x)\n",
    "x_int = x.to(torch.int32)\n",
    "s, e, m = decompose_8bit_e5m2(x_int)\n",
    "print(s, e, m)\n",
    "y = fp8_to_bfloat16(x, n_mantissa)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], dtype=torch.bfloat16)\n",
      "tensor([0], dtype=torch.uint8)\n",
      "tensor([0], dtype=torch.int32) tensor([0], dtype=torch.int32) tensor([0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rounds up: 0\n",
      "Total rounds down: 0\n",
      "Total unchanged: 1\n",
      "Fraction rounded up: 0.0\n",
      "Mean of input: 0.0\n",
      "Mean of output: 0.0\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Generate input in the range [-1, 1]\n",
    "# input = torch.rand(2048, 2048, dtype=torch.bfloat16) + 0.5\n",
    "input = torch.zeros(1, 1, dtype=torch.bfloat16)\n",
    "round_up_count = 0\n",
    "round_down_count = 0\n",
    "\n",
    "for i in range(100):\n",
    "    fp8 = round_to_fp8_represented_as_int8(input, n_mantissa, None)\n",
    "    output = undo_int8_fp8(fp8, n_mantissa)\n",
    "    \n",
    "    # Compare input and output to count rounding directions\n",
    "    rounded_up = (output > input).sum().item()\n",
    "    rounded_down = (output < input).sum().item()\n",
    "    unchanged = (output == input).sum().item()\n",
    "    \n",
    "    round_up_count += rounded_up\n",
    "    round_down_count += rounded_down\n",
    "\n",
    "print(f\"Total rounds up: {round_up_count}\")\n",
    "print(f\"Total rounds down: {round_down_count}\")\n",
    "print(f\"Total unchanged: {unchanged}\")\n",
    "print(f\"Fraction rounded up: {round_up_count / (round_up_count + round_down_count + unchanged)}\")\n",
    "# mean of input and output\n",
    "print(f\"Mean of input: {input.mean()}\")\n",
    "print(f\"Mean of output: {output.mean()}\")\n",
    "\n",
    "\n",
    "    # assert torch.allclose(input.mean(), output.mean(), rtol=1e-02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65536]) tensor([0.0000e+00, 9.1835e-41, 1.8367e-40,  ...,        nan,        nan,\n",
      "               nan], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Construct the full range of bfloat16\n",
    "y = torch.arange(0, 2**16, dtype=torch.int32)\n",
    "y = bits_to_bfloat16(y)\n",
    "print(y.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65536]) tensor([    0,     1,     2,  ..., 65533, 65534, 65535], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "z = bfloat16_to_bits(y)\n",
    "print(z.shape, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP8 E5M2 range:\n",
      "tensor([ 0.0000e+00,  1.5259e-05,  3.0518e-05,  4.5776e-05,  6.1035e-05,\n",
      "         7.6294e-05,  9.1553e-05,  1.0681e-04,  1.2207e-04,  1.5259e-04,\n",
      "         1.8311e-04,  2.1362e-04,  2.4414e-04,  3.0518e-04,  3.6621e-04,\n",
      "         4.2725e-04,  4.8828e-04,  6.1035e-04,  7.3242e-04,  8.5449e-04,\n",
      "         9.7656e-04,  1.2207e-03,  1.4648e-03,  1.7090e-03,  1.9531e-03,\n",
      "         2.4414e-03,  2.9297e-03,  3.4180e-03,  3.9062e-03,  4.8828e-03,\n",
      "         5.8594e-03,  6.8359e-03,  7.8125e-03,  9.7656e-03,  1.1719e-02,\n",
      "         1.3672e-02,  1.5625e-02,  1.9531e-02,  2.3438e-02,  2.7344e-02,\n",
      "         3.1250e-02,  3.9062e-02,  4.6875e-02,  5.4688e-02,  6.2500e-02,\n",
      "         7.8125e-02,  9.3750e-02,  1.0938e-01,  1.2500e-01,  1.5625e-01,\n",
      "         1.8750e-01,  2.1875e-01,  2.5000e-01,  3.1250e-01,  3.7500e-01,\n",
      "         4.3750e-01,  5.0000e-01,  6.2500e-01,  7.5000e-01,  8.7500e-01,\n",
      "         1.0000e+00,  1.2500e+00,  1.5000e+00,  1.7500e+00,  2.0000e+00,\n",
      "         2.5000e+00,  3.0000e+00,  3.5000e+00,  4.0000e+00,  5.0000e+00,\n",
      "         6.0000e+00,  7.0000e+00,  8.0000e+00,  1.0000e+01,  1.2000e+01,\n",
      "         1.4000e+01,  1.6000e+01,  2.0000e+01,  2.4000e+01,  2.8000e+01,\n",
      "         3.2000e+01,  4.0000e+01,  4.8000e+01,  5.6000e+01,  6.4000e+01,\n",
      "         8.0000e+01,  9.6000e+01,  1.1200e+02,  1.2800e+02,  1.6000e+02,\n",
      "         1.9200e+02,  2.2400e+02,  2.5600e+02,  3.2000e+02,  3.8400e+02,\n",
      "         4.4800e+02,  5.1200e+02,  6.4000e+02,  7.6800e+02,  8.9600e+02,\n",
      "         1.0240e+03,  1.2800e+03,  1.5360e+03,  1.7920e+03,  2.0480e+03,\n",
      "         2.5600e+03,  3.0720e+03,  3.5840e+03,  4.0960e+03,  5.1200e+03,\n",
      "         6.1440e+03,  7.1680e+03,  8.1920e+03,  1.0240e+04,  1.2288e+04,\n",
      "         1.4336e+04,  1.6384e+04,  2.0480e+04,  2.4576e+04,  2.8672e+04,\n",
      "         3.2768e+04,  4.0960e+04,  4.9152e+04,  5.7344e+04,         inf,\n",
      "                nan,         nan,         nan, -0.0000e+00, -1.5259e-05,\n",
      "        -3.0518e-05, -4.5776e-05, -6.1035e-05, -7.6294e-05, -9.1553e-05,\n",
      "        -1.0681e-04, -1.2207e-04, -1.5259e-04, -1.8311e-04, -2.1362e-04,\n",
      "        -2.4414e-04, -3.0518e-04, -3.6621e-04, -4.2725e-04, -4.8828e-04,\n",
      "        -6.1035e-04, -7.3242e-04, -8.5449e-04, -9.7656e-04, -1.2207e-03,\n",
      "        -1.4648e-03, -1.7090e-03, -1.9531e-03, -2.4414e-03, -2.9297e-03,\n",
      "        -3.4180e-03, -3.9062e-03, -4.8828e-03, -5.8594e-03, -6.8359e-03,\n",
      "        -7.8125e-03, -9.7656e-03, -1.1719e-02, -1.3672e-02, -1.5625e-02,\n",
      "        -1.9531e-02, -2.3438e-02, -2.7344e-02, -3.1250e-02, -3.9062e-02,\n",
      "        -4.6875e-02, -5.4688e-02, -6.2500e-02, -7.8125e-02, -9.3750e-02,\n",
      "        -1.0938e-01, -1.2500e-01, -1.5625e-01, -1.8750e-01, -2.1875e-01,\n",
      "        -2.5000e-01, -3.1250e-01, -3.7500e-01, -4.3750e-01, -5.0000e-01,\n",
      "        -6.2500e-01, -7.5000e-01, -8.7500e-01, -1.0000e+00, -1.2500e+00,\n",
      "        -1.5000e+00, -1.7500e+00, -2.0000e+00, -2.5000e+00, -3.0000e+00,\n",
      "        -3.5000e+00, -4.0000e+00, -5.0000e+00, -6.0000e+00, -7.0000e+00,\n",
      "        -8.0000e+00, -1.0000e+01, -1.2000e+01, -1.4000e+01, -1.6000e+01,\n",
      "        -2.0000e+01, -2.4000e+01, -2.8000e+01, -3.2000e+01, -4.0000e+01,\n",
      "        -4.8000e+01, -5.6000e+01, -6.4000e+01, -8.0000e+01, -9.6000e+01,\n",
      "        -1.1200e+02, -1.2800e+02, -1.6000e+02, -1.9200e+02, -2.2400e+02,\n",
      "        -2.5600e+02, -3.2000e+02, -3.8400e+02, -4.4800e+02, -5.1200e+02,\n",
      "        -6.4000e+02, -7.6800e+02, -8.9600e+02, -1.0240e+03, -1.2800e+03,\n",
      "        -1.5360e+03, -1.7920e+03, -2.0480e+03, -2.5600e+03, -3.0720e+03,\n",
      "        -3.5840e+03, -4.0960e+03, -5.1200e+03, -6.1440e+03, -7.1680e+03,\n",
      "        -8.1920e+03, -1.0240e+04, -1.2288e+04, -1.4336e+04, -1.6384e+04,\n",
      "        -2.0480e+04, -2.4576e+04, -2.8672e+04, -3.2768e+04, -4.0960e+04,\n",
      "        -4.9152e+04, -5.7344e+04,        -inf,         nan,         nan,\n",
      "                nan])\n"
     ]
    }
   ],
   "source": [
    "# Construct the full range of uint8\n",
    "x = torch.arange(0, 2**8, dtype=torch.int32)\n",
    "s, e, m = decompose_8bit_e5m2(x)\n",
    "# Generate fp8 e5m2 as floating points\n",
    "fp8_e5m2 = torch.zeros(256, dtype=torch.float32)\n",
    "\n",
    "for i in range(256):\n",
    "    sign = (i & 0b10000000) >> 7\n",
    "    exponent = (i & 0b01111100) >> 2\n",
    "    mantissa = i & 0b00000011\n",
    "\n",
    "    # Handle special cases\n",
    "    if exponent == 0:\n",
    "        if mantissa == 0:\n",
    "            # Zero\n",
    "            fp8_e5m2[i] = 0.0 if sign == 0 else -0.0\n",
    "        else:\n",
    "            # Subnormal numbers\n",
    "            fp8_e5m2[i] = ((-1)**sign) * (2**-14) * (mantissa / 4)\n",
    "    elif exponent == 31:\n",
    "        if mantissa == 0:\n",
    "            # Infinity\n",
    "            fp8_e5m2[i] = float('inf') if sign == 0 else float('-inf')\n",
    "        else:\n",
    "            # NaN\n",
    "            fp8_e5m2[i] = float('nan')\n",
    "    else:\n",
    "        # Normal numbers\n",
    "        fp8_e5m2[i] = ((-1)**sign) * (2**(exponent - 15)) * (1 + mantissa / 4)\n",
    "\n",
    "print(\"FP8 E5M2 range:\")\n",
    "print(fp8_e5m2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 1, 1, 1], dtype=torch.int32) tensor([  0,   0,   0,  ..., 255, 255, 255], dtype=torch.int32) tensor([  0,   1,   2,  ..., 125, 126, 127], dtype=torch.int32)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32) tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15], dtype=torch.int32) tensor([0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "        0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7], dtype=torch.int32)\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32) tensor([ 0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3,  4,  4,\n",
      "         4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  8,\n",
      "         9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 12, 13, 13,\n",
      "        13, 13, 14, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 16, 17, 17, 17, 17,\n",
      "        18, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22,\n",
      "        22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26,\n",
      "        27, 27, 27, 27, 28, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30, 31, 31,\n",
      "        31, 31,  0,  0,  0,  0,  1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3,\n",
      "         4,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,  7,  7,  8,  8,\n",
      "         8,  8,  9,  9,  9,  9, 10, 10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 12,\n",
      "        13, 13, 13, 13, 14, 14, 14, 14, 15, 15, 15, 15, 16, 16, 16, 16, 17, 17,\n",
      "        17, 17, 18, 18, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21,\n",
      "        22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26,\n",
      "        26, 26, 27, 27, 27, 27, 28, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30,\n",
      "        31, 31, 31, 31], dtype=torch.int32) tensor([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(*decompose_16bit(z))\n",
    "print(*decompose_8bit_e4m3(x))\n",
    "print(*decompose_8bit_e5m2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "sign, exponent, mantissa = decompose_16bit(z)\n",
    "bits = compose_16bit(sign, exponent, mantissa)\n",
    "print(torch.equal(bits, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that you can convert bfloat16 to bits and back\n",
    "y_ = bits_to_bfloat16(\n",
    "    bfloat16_to_bits(y)\n",
    ")\n",
    "comparison = torch.isclose(\n",
    "        y,\n",
    "        y_\n",
    ")\n",
    "comparison[torch.isnan(y) & torch.isnan(y_)] = True\n",
    "comparison.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that you can convert bfloat16 to bits, decompose, recompose and convert back\n",
    "y_bits = bfloat16_to_bits(y)\n",
    "components = decompose_16bit(y_bits)\n",
    "y_bits_ = compose_16bit(*components)\n",
    "y_ = bits_to_bfloat16(y_bits_)\n",
    "\n",
    "comparison = torch.isclose(\n",
    "        y,\n",
    "        y_\n",
    ")\n",
    "comparison[torch.isnan(y) & torch.isnan(y_)] = True\n",
    "comparison.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([inf], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Construct infinity\n",
    "s = torch.tensor([0], dtype=torch.int32)\n",
    "e = torch.tensor([0xFF], dtype=torch.int32)\n",
    "m = torch.tensor([0], dtype=torch.int32)\n",
    "n = bits_to_bfloat16(compose_16bit(s, e, m))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([nan], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Construct nan\n",
    "s = torch.tensor([0], dtype=torch.int32)\n",
    "e = torch.tensor([0xFF], dtype=torch.int32)\n",
    "m = torch.tensor([1], dtype=torch.int32)\n",
    "n = bits_to_bfloat16(compose_16bit(s, e, m))\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3125], dtype=torch.bfloat16) tensor([0.3125], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Test bfloat16 to e5m2 and back\n",
    "t = torch.tensor([0.3125], dtype=torch.bfloat16)\n",
    "t_bits = bfloat16_to_bits(t)\n",
    "\n",
    "encoded = encode_as_e5m2_trunc(t_bits)\n",
    "decoded = decode_from_e5m2(encoded)\n",
    "t_quantized = bits_to_bfloat16(decoded)\n",
    "print(t, t_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([0.2178], dtype=torch.bfloat16)\n",
      "Quantized: tensor([0.2188], dtype=torch.bfloat16)\n",
      "Rounded up correctly: tensor([True])\n"
     ]
    }
   ],
   "source": [
    "# Test rounding up when converting from bfloat16 to e5m2\n",
    "s = torch.tensor([0], dtype=torch.int32)\n",
    "e = torch.tensor([0b01111100], dtype=torch.int32)\n",
    "m = torch.tensor([0b1011111], dtype=torch.int32)  # Changed to 1011111 to test rounding up\n",
    "t_bits = compose_16bit(s, e, m)\n",
    "t = bits_to_bfloat16(t_bits)  # This is 0 01111100 1011111 in binary\n",
    "\n",
    "encoded = encode_as_e5m2_round_up(t_bits)\n",
    "decoded = decode_from_e5m2(encoded)\n",
    "t_quantized = bits_to_bfloat16(decoded)\n",
    "\n",
    "# Construct the rounded up e5m2 value\n",
    "encoded_e5m2 = encode_as_e5m2_trunc(t_bits)\n",
    "s, e, m = decompose_8bit_e5m2(encoded_e5m2)\n",
    "\n",
    "# Manually round up (without worrying about mantissa overflow)\n",
    "m += 1\n",
    "\n",
    "# Compose the rounded e5m2 value\n",
    "rounded_e5m2 = compose_e5m2(s, e, m)\n",
    "\n",
    "# Convert back to bfloat16 using decode_from_e5m2\n",
    "decoded_bits = decode_from_e5m2(rounded_e5m2)\n",
    "t_expected = bits_to_bfloat16(decoded_bits)\n",
    "\n",
    "print(\"Original:\", t)\n",
    "print(\"Quantized:\", t_quantized)\n",
    "print(\"Rounded up correctly:\", torch.isclose(t_quantized, t_expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding-decoding process is reversible for all e5m2 values: True\n"
     ]
    }
   ],
   "source": [
    "# Test encode_as_e5m2 and decode_as_e5m2 for all possible e5m2 values\n",
    "\n",
    "# Generate all possible 8-bit values (0 to 255)\n",
    "all_e5m2_values = torch.arange(0, 256, dtype=torch.uint8)\n",
    "\n",
    "# Convert to int32 for compatibility with our functions\n",
    "all_e5m2_int32 = all_e5m2_values.to(dtype=torch.int32)\n",
    "\n",
    "# Decode all e5m2 values to bfloat16 bits\n",
    "decoded_bits = decode_from_e5m2(all_e5m2_int32)\n",
    "\n",
    "# Convert to bfloat16\n",
    "bfloat16_values = bits_to_bfloat16(decoded_bits)\n",
    "\n",
    "# Encode back to e5m2\n",
    "encoded_e5m2 = encode_as_e5m2_trunc(bfloat16_to_bits(bfloat16_values))\n",
    "\n",
    "# Check if the encoding-decoding process is reversible\n",
    "is_reversible = torch.all(encoded_e5m2 == all_e5m2_int32)\n",
    "\n",
    "print(f\"Encoding-decoding process is reversible for all e5m2 values: {is_reversible}\")\n",
    "\n",
    "# Additional checks\n",
    "if not is_reversible:\n",
    "    # Find where the mismatch occurs\n",
    "    mismatch = encoded_e5m2 != all_e5m2_int32\n",
    "    mismatch_indices = torch.where(mismatch)[0]\n",
    "    print(f\"Mismatches found at indices: {mismatch_indices}\")\n",
    "    \n",
    "    # Print a few mismatched values for inspection\n",
    "    for idx in mismatch_indices[:5]:  # Show first 5 mismatches\n",
    "        original = all_e5m2_int32[idx].item()\n",
    "        encoded = encoded_e5m2[idx].item()\n",
    "        print(f\"Index {idx}: Original {original:08b}, Encoded {encoded:08b}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounding process preserves order (ignoring NaNs): False\n"
     ]
    }
   ],
   "source": [
    "# Test round_to_fp8_represented_as_int8() and undo_int8_fp8() for all bfloat16 values\n",
    "\n",
    "# Generate all possible 16-bit values (0 to 65535)\n",
    "all_bfloat16_values = torch.arange(0, 2**16, dtype=torch.int32)\n",
    "\n",
    "# Convert to bfloat16\n",
    "bfloat16_values = bits_to_bfloat16(all_bfloat16_values)\n",
    "\n",
    "# Round to fp8 (e5m2)\n",
    "fp8_values = round_to_fp8_represented_as_int8(bfloat16_values, n_mantissa=2)\n",
    "\n",
    "# Convert back to bfloat16\n",
    "recovered_bfloat16 = undo_int8_fp8(fp8_values, n_mantissa=2)\n",
    "\n",
    "# Create a mask for non-NaN values\n",
    "non_nan_mask = ~torch.isnan(bfloat16_values) & ~torch.isnan(recovered_bfloat16)\n",
    "\n",
    "# Check if the rounding process preserves order (ignoring NaNs)\n",
    "is_order_preserved = torch.all(torch.argsort(bfloat16_values[non_nan_mask]) == torch.argsort(recovered_bfloat16[non_nan_mask]))\n",
    "\n",
    "print(f\"Rounding process preserves order (ignoring NaNs): {is_order_preserved}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0000,  2.0000,  2.5000,  ..., -0.8750, -0.8750, -1.2500],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are able to:\n",
    "- Construct the full range of bfloat16, uint8\n",
    "- Convert bfloat16 to bits and back\n",
    "- Convert bfloat16 to sign, exponent, mantissa and back\n",
    "- Test that conversion is correct except NaN values\n",
    "- Truncate when bfloat16 to e5m2 with mantissa chopping\n",
    "- Round up when converting from bfloat16 to e5m2\n",
    "\n",
    "Next:\n",
    "- Handle subnormal, inf, nan special cases in encode and decode \n",
    "- Round by stochastic rounding scheme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
